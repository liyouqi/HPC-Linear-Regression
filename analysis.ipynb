{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d52094",
   "metadata": {},
   "source": [
    "# Parallel Linear Regression - Performance Analysis\n",
    "\n",
    "This notebook analyzes the performance results from Strong Scaling experiments of parallel linear regression implementations (OLS and GD) using MPI.\n",
    "\n",
    "**Analysis Goals:**\n",
    "- Calculate Speedup and Efficiency metrics\n",
    "- Compare OLS vs GD parallel performance\n",
    "- Fit Amdahl's Law to quantify serial fraction\n",
    "- Generate publication-quality plots for the technical report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca9b53",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c121e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Set plot style for professional appearance\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7331bfd",
   "metadata": {},
   "source": [
    "## 2. Load Experimental Data\n",
    "\n",
    "Load CSV files from the `results/` directory. Expected filename format:\n",
    "- `ols_n{N}_d{D}_p{P}_run{R}.csv` for OLS\n",
    "- `gd_n{N}_d{D}_p{P}_run{R}.csv` for GD\n",
    "\n",
    "Where:\n",
    "- N = number of samples\n",
    "- D = number of features\n",
    "- P = number of processes\n",
    "- R = run number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "RESULTS_DIR = 'results/'\n",
    "PLOTS_DIR = 'plots/'\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "def load_experimental_data(algorithm='ols', n=100000, d=100):\n",
    "    \"\"\"\n",
    "    Load experimental results from CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    - algorithm: 'ols' or 'gd'\n",
    "    - n: number of samples\n",
    "    - d: number of features\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns: [nprocs, run, time]\n",
    "    \"\"\"\n",
    "    pattern = f\"{RESULTS_DIR}{algorithm}_n{n}_d{d}_p*_run*.csv\"\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ö†Ô∏è  No files found matching pattern: {pattern}\")\n",
    "        return None\n",
    "    \n",
    "    data = []\n",
    "    for file in files:\n",
    "        # Extract nprocs and run from filename\n",
    "        basename = os.path.basename(file)\n",
    "        parts = basename.replace('.csv', '').split('_')\n",
    "        \n",
    "        # Find p and run values\n",
    "        nprocs = int([p for p in parts if p.startswith('p')][0][1:])\n",
    "        run = int([r for r in parts if r.startswith('run')][0][3:])\n",
    "        \n",
    "        # Read CSV (assuming it contains timing data)\n",
    "        df = pd.read_csv(file)\n",
    "        # Assuming CSV has a 'time' column or similar\n",
    "        time = df['time'].values[0] if 'time' in df.columns else df.iloc[0, 0]\n",
    "        \n",
    "        data.append({\n",
    "            'nprocs': nprocs,\n",
    "            'run': run,\n",
    "            'time': time\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"‚úÖ Loaded {len(files)} files for {algorithm.upper()}\")\n",
    "    print(f\"   Process counts: {sorted(df['nprocs'].unique())}\")\n",
    "    print(f\"   Runs per configuration: {df.groupby('nprocs').size().values}\")\n",
    "    \n",
    "    return df.sort_values('nprocs')\n",
    "\n",
    "# Try to load data (will show warning if files don't exist yet)\n",
    "ols_data = load_experimental_data('ols')\n",
    "gd_data = load_experimental_data('gd')\n",
    "\n",
    "# Display sample data\n",
    "if ols_data is not None:\n",
    "    print(\"\\nSample OLS data:\")\n",
    "    display(ols_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06bf6de",
   "metadata": {},
   "source": [
    "## 3. Data Aggregation and Statistics\n",
    "\n",
    "Aggregate multiple runs for each configuration to compute mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(df):\n",
    "    \"\"\"\n",
    "    Aggregate experimental data by computing mean and std for each process count.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns: [nprocs, time_mean, time_std, runs_count]\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    agg = df.groupby('nprocs')['time'].agg([\n",
    "        ('time_mean', 'mean'),\n",
    "        ('time_std', 'std'),\n",
    "        ('runs_count', 'count')\n",
    "    ]).reset_index()\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Aggregate data\n",
    "ols_agg = aggregate_data(ols_data)\n",
    "gd_agg = aggregate_data(gd_data)\n",
    "\n",
    "# Display aggregated data\n",
    "if ols_agg is not None:\n",
    "    print(\"OLS Aggregated Results:\")\n",
    "    display(ols_agg)\n",
    "    \n",
    "if gd_agg is not None:\n",
    "    print(\"\\nGD Aggregated Results:\")\n",
    "    display(gd_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294dafd",
   "metadata": {},
   "source": [
    "## 4. Compute Performance Metrics\n",
    "\n",
    "Calculate Speedup and Efficiency:\n",
    "- **Speedup**: $S_p = T_1 / T_p$\n",
    "- **Efficiency**: $E_p = S_p / p = T_1 / (p \\cdot T_p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(agg_df):\n",
    "    \"\"\"\n",
    "    Compute Speedup and Efficiency metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - agg_df: Aggregated DataFrame with time_mean column\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added columns: [speedup, efficiency]\n",
    "    \"\"\"\n",
    "    if agg_df is None:\n",
    "        return None\n",
    "    \n",
    "    df = agg_df.copy()\n",
    "    \n",
    "    # Get baseline time (p=1)\n",
    "    T1 = df[df['nprocs'] == 1]['time_mean'].values[0]\n",
    "    \n",
    "    # Calculate speedup and efficiency\n",
    "    df['speedup'] = T1 / df['time_mean']\n",
    "    df['efficiency'] = df['speedup'] / df['nprocs']\n",
    "    \n",
    "    # Calculate speedup error propagation (if std available)\n",
    "    if 'time_std' in df.columns:\n",
    "        T1_std = df[df['nprocs'] == 1]['time_std'].values[0]\n",
    "        # Error propagation for S = T1/Tp\n",
    "        df['speedup_std'] = df['speedup'] * np.sqrt(\n",
    "            (T1_std / T1)**2 + (df['time_std'] / df['time_mean'])**2\n",
    "        )\n",
    "        df['efficiency_std'] = df['speedup_std'] / df['nprocs']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Compute metrics\n",
    "ols_metrics = compute_metrics(ols_agg)\n",
    "gd_metrics = compute_metrics(gd_agg)\n",
    "\n",
    "# Display metrics\n",
    "if ols_metrics is not None:\n",
    "    print(\"OLS Performance Metrics:\")\n",
    "    display(ols_metrics[['nprocs', 'time_mean', 'speedup', 'efficiency']])\n",
    "    \n",
    "if gd_metrics is not None:\n",
    "    print(\"\\nGD Performance Metrics:\")\n",
    "    display(gd_metrics[['nprocs', 'time_mean', 'speedup', 'efficiency']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152cdbc8",
   "metadata": {},
   "source": [
    "## 5. Speedup Plot\n",
    "\n",
    "Plot Speedup vs Number of Processes with ideal linear speedup line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speedup(ols_df, gd_df=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Create Speedup vs Processes plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    # Plot OLS\n",
    "    if ols_df is not None:\n",
    "        ax.plot(ols_df['nprocs'], ols_df['speedup'], \n",
    "                'o-', label='OLS', color='#2E86AB', linewidth=2.5, markersize=10)\n",
    "        if 'speedup_std' in ols_df.columns:\n",
    "            ax.errorbar(ols_df['nprocs'], ols_df['speedup'], \n",
    "                       yerr=ols_df['speedup_std'], fmt='none', \n",
    "                       color='#2E86AB', alpha=0.3, capsize=5)\n",
    "    \n",
    "    # Plot GD\n",
    "    if gd_df is not None:\n",
    "        ax.plot(gd_df['nprocs'], gd_df['speedup'], \n",
    "                's-', label='GD', color='#A23B72', linewidth=2.5, markersize=10)\n",
    "        if 'speedup_std' in gd_df.columns:\n",
    "            ax.errorbar(gd_df['nprocs'], gd_df['speedup'], \n",
    "                       yerr=gd_df['speedup_std'], fmt='none', \n",
    "                       color='#A23B72', alpha=0.3, capsize=5)\n",
    "    \n",
    "    # Plot ideal speedup line\n",
    "    max_p = max(ols_df['nprocs'].max() if ols_df is not None else 1,\n",
    "                gd_df['nprocs'].max() if gd_df is not None else 1)\n",
    "    ideal_p = np.arange(1, max_p + 1)\n",
    "    ax.plot(ideal_p, ideal_p, '--', label='Ideal (Linear)', \n",
    "            color='gray', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Number of Processes', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Speedup', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Strong Scaling: Speedup vs Number of Processes', \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper left', frameon=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_xticks(ideal_p)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Speedup plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate plot\n",
    "plot_speedup(ols_metrics, gd_metrics, save_path=f'{PLOTS_DIR}speedup.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d5b0e",
   "metadata": {},
   "source": [
    "## 6. Efficiency Plot\n",
    "\n",
    "Plot Efficiency vs Number of Processes with 100% reference line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_efficiency(ols_df, gd_df=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Create Efficiency vs Processes plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    # Plot OLS\n",
    "    if ols_df is not None:\n",
    "        ax.plot(ols_df['nprocs'], ols_df['efficiency'] * 100, \n",
    "                'o-', label='OLS', color='#2E86AB', linewidth=2.5, markersize=10)\n",
    "        if 'efficiency_std' in ols_df.columns:\n",
    "            ax.errorbar(ols_df['nprocs'], ols_df['efficiency'] * 100, \n",
    "                       yerr=ols_df['efficiency_std'] * 100, fmt='none', \n",
    "                       color='#2E86AB', alpha=0.3, capsize=5)\n",
    "    \n",
    "    # Plot GD\n",
    "    if gd_df is not None:\n",
    "        ax.plot(gd_df['nprocs'], gd_df['efficiency'] * 100, \n",
    "                's-', label='GD', color='#A23B72', linewidth=2.5, markersize=10)\n",
    "        if 'efficiency_std' in gd_df.columns:\n",
    "            ax.errorbar(gd_df['nprocs'], gd_df['efficiency'] * 100, \n",
    "                       yerr=gd_df['efficiency_std'] * 100, fmt='none', \n",
    "                       color='#A23B72', alpha=0.3, capsize=5)\n",
    "    \n",
    "    # Reference lines\n",
    "    max_p = max(ols_df['nprocs'].max() if ols_df is not None else 1,\n",
    "                gd_df['nprocs'].max() if gd_df is not None else 1)\n",
    "    ax.axhline(y=100, color='gray', linestyle='--', linewidth=2, \n",
    "               label='100% (Ideal)', alpha=0.7)\n",
    "    ax.axhline(y=80, color='orange', linestyle=':', linewidth=1.5, \n",
    "               label='80% (Good)', alpha=0.5)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Number of Processes', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Efficiency (%)', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Strong Scaling: Parallel Efficiency vs Number of Processes', \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='lower left', frameon=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_ylim(0, 110)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Efficiency plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate plot\n",
    "plot_efficiency(ols_metrics, gd_metrics, save_path=f'{PLOTS_DIR}efficiency.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c2bec",
   "metadata": {},
   "source": [
    "## 7. Amdahl's Law Analysis\n",
    "\n",
    "Fit Amdahl's Law to experimental data:\n",
    "\n",
    "$$S_p = \\frac{1}{f + \\frac{1-f}{p}}$$\n",
    "\n",
    "Where:\n",
    "- $f$ = serial fraction\n",
    "- $S_p$ = speedup with $p$ processes\n",
    "\n",
    "Theoretical maximum speedup: $S_{\\infty} = 1/f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643892a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amdahl_law(p, f):\n",
    "    \"\"\"Amdahl's Law function\"\"\"\n",
    "    return 1.0 / (f + (1 - f) / p)\n",
    "\n",
    "def fit_amdahl(df):\n",
    "    \"\"\"\n",
    "    Fit Amdahl's Law to speedup data.\n",
    "    \n",
    "    Returns:\n",
    "    - f: serial fraction\n",
    "    - S_inf: theoretical maximum speedup\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    \n",
    "    p_values = df['nprocs'].values\n",
    "    speedup_values = df['speedup'].values\n",
    "    \n",
    "    # Fit using curve_fit\n",
    "    popt, pcov = curve_fit(amdahl_law, p_values, speedup_values, \n",
    "                           p0=[0.05], bounds=(0, 1))\n",
    "    \n",
    "    f = popt[0]\n",
    "    S_inf = 1.0 / f\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    residuals = speedup_values - amdahl_law(p_values, f)\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((speedup_values - np.mean(speedup_values))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(f\"Serial Fraction (f): {f:.4f} ({f*100:.2f}%)\")\n",
    "    print(f\"Theoretical Max Speedup (S‚àû): {S_inf:.2f}√ó\")\n",
    "    print(f\"R¬≤ (goodness of fit): {r_squared:.4f}\")\n",
    "    \n",
    "    return f, S_inf\n",
    "\n",
    "# Fit Amdahl's Law for OLS\n",
    "if ols_metrics is not None:\n",
    "    print(\"OLS Amdahl's Law Fit:\")\n",
    "    ols_f, ols_sinf = fit_amdahl(ols_metrics)\n",
    "    print()\n",
    "\n",
    "# Fit for GD\n",
    "if gd_metrics is not None:\n",
    "    print(\"GD Amdahl's Law Fit:\")\n",
    "    gd_f, gd_sinf = fit_amdahl(gd_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d2b08",
   "metadata": {},
   "source": [
    "## 8. Amdahl's Law Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amdahl(df, f, S_inf, algorithm='OLS', save_path=None):\n",
    "    \"\"\"\n",
    "    Plot Amdahl's Law fit with experimental data.\n",
    "    \"\"\"\n",
    "    if df is None or f is None:\n",
    "        print(\"‚ö†Ô∏è  No data available for Amdahl plot\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    # Experimental data\n",
    "    ax.plot(df['nprocs'], df['speedup'], 'o', \n",
    "            label=f'{algorithm} (Measured)', color='#2E86AB', markersize=10)\n",
    "    \n",
    "    # Amdahl's Law fit\n",
    "    p_fit = np.linspace(1, df['nprocs'].max() * 1.5, 100)\n",
    "    speedup_fit = amdahl_law(p_fit, f)\n",
    "    ax.plot(p_fit, speedup_fit, '-', \n",
    "            label=f\"Amdahl's Law (f={f:.4f})\", color='#F18F01', linewidth=2.5)\n",
    "    \n",
    "    # Ideal speedup\n",
    "    ax.plot(p_fit, p_fit, '--', label='Ideal (Linear)', \n",
    "            color='gray', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Theoretical limit\n",
    "    ax.axhline(y=S_inf, color='red', linestyle=':', linewidth=2, \n",
    "               label=f'Theoretical Limit (S‚àû={S_inf:.1f}√ó)', alpha=0.7)\n",
    "    \n",
    "    # Annotations\n",
    "    ax.text(df['nprocs'].max() * 0.6, S_inf * 0.9, \n",
    "            f'Serial Fraction: {f*100:.2f}%\\nMax Speedup: {S_inf:.2f}√ó',\n",
    "            fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Number of Processes', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Speedup', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f\"{algorithm}: Amdahl's Law Analysis\", \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='lower right', frameon=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Amdahl plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate Amdahl plots\n",
    "if ols_metrics is not None and ols_f is not None:\n",
    "    plot_amdahl(ols_metrics, ols_f, ols_sinf, 'OLS', \n",
    "                save_path=f'{PLOTS_DIR}amdahl_ols.png')\n",
    "\n",
    "if gd_metrics is not None and gd_f is not None:\n",
    "    plot_amdahl(gd_metrics, gd_f, gd_sinf, 'GD', \n",
    "                save_path=f'{PLOTS_DIR}amdahl_gd.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26dfdc",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6121c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(ols_df, gd_df=None):\n",
    "    \"\"\"\n",
    "    Create a summary table for the report.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    if ols_df is not None:\n",
    "        for _, row in ols_df.iterrows():\n",
    "            summary_data.append({\n",
    "                'Algorithm': 'OLS',\n",
    "                'Processes': int(row['nprocs']),\n",
    "                'Time (s)': f\"{row['time_mean']:.3f} ¬± {row.get('time_std', 0):.3f}\",\n",
    "                'Speedup': f\"{row['speedup']:.2f}√ó\",\n",
    "                'Efficiency': f\"{row['efficiency']*100:.1f}%\"\n",
    "            })\n",
    "    \n",
    "    if gd_df is not None:\n",
    "        for _, row in gd_df.iterrows():\n",
    "            summary_data.append({\n",
    "                'Algorithm': 'GD',\n",
    "                'Processes': int(row['nprocs']),\n",
    "                'Time (s)': f\"{row['time_mean']:.3f} ¬± {row.get('time_std', 0):.3f}\",\n",
    "                'Speedup': f\"{row['speedup']:.2f}√ó\",\n",
    "                'Efficiency': f\"{row['efficiency']*100:.1f}%\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n",
    "\n",
    "# Create and display summary table\n",
    "summary_table = create_summary_table(ols_metrics, gd_metrics)\n",
    "\n",
    "if not summary_table.empty:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PERFORMANCE SUMMARY TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    display(summary_table)\n",
    "    \n",
    "    # Save to CSV\n",
    "    summary_table.to_csv(f'{RESULTS_DIR}summary_table.csv', index=False)\n",
    "    print(f\"\\n‚úÖ Summary table saved to: {RESULTS_DIR}summary_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48024970",
   "metadata": {},
   "source": [
    "## 10. Key Findings and Insights\n",
    "\n",
    "This section summarizes the main observations from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb37681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key findings\n",
    "print(\"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if ols_metrics is not None:\n",
    "    max_p_ols = ols_metrics['nprocs'].max()\n",
    "    max_speedup_ols = ols_metrics['speedup'].max()\n",
    "    eff_at_max_ols = ols_metrics[ols_metrics['nprocs'] == max_p_ols]['efficiency'].values[0]\n",
    "    \n",
    "    print(\"\\nüìä OLS Performance:\")\n",
    "    print(f\"  ‚Ä¢ Maximum speedup: {max_speedup_ols:.2f}√ó (with {max_p_ols} processes)\")\n",
    "    print(f\"  ‚Ä¢ Efficiency at max processes: {eff_at_max_ols*100:.1f}%\")\n",
    "    if ols_f:\n",
    "        print(f\"  ‚Ä¢ Serial fraction: {ols_f*100:.2f}%\")\n",
    "        print(f\"  ‚Ä¢ Theoretical maximum: {ols_sinf:.2f}√ó\")\n",
    "\n",
    "if gd_metrics is not None:\n",
    "    max_p_gd = gd_metrics['nprocs'].max()\n",
    "    max_speedup_gd = gd_metrics['speedup'].max()\n",
    "    eff_at_max_gd = gd_metrics[gd_metrics['nprocs'] == max_p_gd]['efficiency'].values[0]\n",
    "    \n",
    "    print(\"\\nüìä GD Performance:\")\n",
    "    print(f\"  ‚Ä¢ Maximum speedup: {max_speedup_gd:.2f}√ó (with {max_p_gd} processes)\")\n",
    "    print(f\"  ‚Ä¢ Efficiency at max processes: {eff_at_max_gd*100:.1f}%\")\n",
    "    if gd_f:\n",
    "        print(f\"  ‚Ä¢ Serial fraction: {gd_f*100:.2f}%\")\n",
    "        print(f\"  ‚Ä¢ Theoretical maximum: {gd_sinf:.2f}√ó\")\n",
    "\n",
    "if ols_metrics is not None and gd_metrics is not None:\n",
    "    print(\"\\nüîÑ OLS vs GD Comparison:\")\n",
    "    speedup_diff = max_speedup_ols - max_speedup_gd\n",
    "    eff_diff = (eff_at_max_ols - eff_at_max_gd) * 100\n",
    "    print(f\"  ‚Ä¢ Speedup difference: {speedup_diff:.2f}√ó (OLS is faster)\")\n",
    "    print(f\"  ‚Ä¢ Efficiency difference: {eff_diff:.1f}% (OLS is more efficient)\")\n",
    "    print(\"  ‚Ä¢ Reason: GD has higher communication overhead due to iterative updates\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd64f3",
   "metadata": {},
   "source": [
    "## 11. Export All Plots\n",
    "\n",
    "Summary of all generated plots (ready for inclusion in technical report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\nüìÅ Generated Plots:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "plot_files = [\n",
    "    'speedup.png',\n",
    "    'efficiency.png',\n",
    "    'amdahl_ols.png',\n",
    "    'amdahl_gd.png'\n",
    "]\n",
    "\n",
    "for plot_file in plot_files:\n",
    "    full_path = os.path.join(PLOTS_DIR, plot_file)\n",
    "    if os.path.exists(full_path):\n",
    "        size = os.path.getsize(full_path) / 1024  # KB\n",
    "        print(f\"‚úÖ {plot_file:25s} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {plot_file:25s} (not generated)\")\n",
    "\n",
    "print(\"\\nüí° All plots are saved in high resolution (300 DPI) and ready for report inclusion.\")\n",
    "print(f\"üìÇ Location: {os.path.abspath(PLOTS_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562265a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**Usage Instructions:**\n",
    "1. After running experiments on the cluster, download all CSV files to `results/` directory\n",
    "2. Run all cells in this notebook (Cell ‚Üí Run All)\n",
    "3. Review generated plots in `plots/` directory\n",
    "4. Use the summary table and key findings for your technical report\n",
    "\n",
    "**Data Format Expected:**\n",
    "- CSV files should contain at least a 'time' column with execution time in seconds\n",
    "- Filename format: `{algorithm}_n{N}_d{D}_p{P}_run{R}.csv`\n",
    "\n",
    "**Customization:**\n",
    "- Adjust plot colors, styles, and sizes in the plotting functions\n",
    "- Modify figure sizes by changing `figsize` parameter\n",
    "- Add more metrics or plots as needed\n",
    "\n",
    "---\n",
    "*Analysis completed on: January 10, 2026*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
